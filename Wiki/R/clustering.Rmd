---
title: "Clustering"
date: "`r format(Sys.time(), '%d %B, %Y')`"
---


# K-Means

```{r, warning=F}
iris[1:3,]

model <- kmeans(iris[,1:4], 3)
# plot with first two attributes: Sepal.Length Sepal.Width 
plot(iris[,1], iris[,2], col=model$cluster)
# point center of first two attributes
points(model$centers[, c(1,2)], col=1:3, pch=8, cex=2)

```


more : http://www.mattpeeples.net/kmeans.html

# Hierarchical Clustering

```{r}
sampleiris <- iris[sample(1:150, 30),]
distance <- dist(sampleiris[,-5], method="euclidean")
model <- hclust(distance, method="average")
plot(model, hang=-1, label=sampleiris$Species)
```

# Fuzzy C-Means

```{r, warning=F}
library(e1071)
model <- cmeans(iris[,-5], 3, 100, m=2, method="cmeans")
plot(iris[,1], iris[,2], col=model$cluster)
points(model$centers[,c(1,2)], col=1:3, pch=8, cex=2)

```

# Density-based Cluster

```{r, warning=F}
sampleiris <- iris[sample(1:150, 40),]
library(fpc)
# eps is radius of neighborhood, MinPts is no of neighbors within eps
model <- dbscan(sampleiris[,-5], eps=0.6, MinPts=4)
# plot(model, sampleiris)
# Notice points in cluster 0 are unassigned outliers
plot(model, sampleiris[,c(1,4)])

```

# Multi-Gaussian with Expectation-Maximization

```{r, warning=F}
library(mclust)
model <- Mclust(iris[,1:4], 3)
plot(model, iris[, 1:4], what=c('classification'), dimens=c(3,4))
```

----------

references: 

http://horicky.blogspot.ie/2012/04/machine-learning-in-r-clustering.html


